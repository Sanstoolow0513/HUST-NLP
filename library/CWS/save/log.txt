2025-0509 20:56:08 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 20:56:08 INFO     使用BERT模型: bert-base-chinese
2025-0509 20:56:08 DEBUG    Starting new HTTPS connection (1): huggingface.co:443
2025-0509 20:56:10 DEBUG    https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/vocab.txt HTTP/1.1" 200 0
2025-0509 20:56:10 DEBUG    Starting new HTTPS connection (1): huggingface.co:443
2025-0509 20:56:14 DEBUG    https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer.json HTTP/1.1" 200 0
2025-0509 20:56:14 DEBUG    Starting new HTTPS connection (1): huggingface.co:443
2025-0509 20:56:17 DEBUG    https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/1.1" 200 0
2025-0509 20:56:17 DEBUG    Starting new HTTPS connection (1): huggingface.co:443
2025-0509 20:56:19 DEBUG    https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/pytorch_model.bin HTTP/1.1" 302 0
2025-0509 20:56:20 INFO     训练集标签统计:
2025-0509 20:56:20 INFO     验证集标签统计:
2025-0509 20:56:22 DEBUG    bert.embeddings.word_embeddings.weight: torch.Size([21128, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.embeddings.position_embeddings.weight: torch.Size([512, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.embeddings.token_type_embeddings.weight: torch.Size([2, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.embeddings.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.embeddings.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.0.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.1.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.2.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.3.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.4.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.5.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.6.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.7.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.8.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.9.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.10.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.self.query.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.self.query.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.self.key.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.self.key.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.self.value.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.self.value.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.output.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.attention.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.intermediate.dense.weight: torch.Size([3072, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.intermediate.dense.bias: torch.Size([3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.output.dense.weight: torch.Size([768, 3072]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.output.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.output.LayerNorm.weight: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.encoder.layer.11.output.LayerNorm.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.pooler.dense.weight: torch.Size([768, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    bert.pooler.dense.bias: torch.Size([768]), require_grad=True
2025-0509 20:56:22 DEBUG    hidden2tag.weight: torch.Size([5, 768]), require_grad=True
2025-0509 20:56:22 DEBUG    hidden2tag.bias: torch.Size([5]), require_grad=True
2025-0509 20:56:22 DEBUG    crf.start_transitions: torch.Size([5]), require_grad=True
2025-0509 20:56:22 DEBUG    crf.end_transitions: torch.Size([5]), require_grad=True
2025-0509 20:56:22 DEBUG    crf.transitions: torch.Size([5, 5]), require_grad=True
2025-0509 21:05:44 DEBUG    epoch 0-step 1000 loss: 5.990589
2025-0509 21:05:44 INFO     Step 1000: 开始验证...
2025-0509 21:05:44 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:06:31 INFO     Step 1000 验证结果 - precision: 0.9738, recall: 0.9663, fscore: 0.9701
2025-0509 21:07:18 INFO     在验证集上评估...
2025-0509 21:07:18 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:08:02 INFO     验证集 - precision: 0.974595, recall: 0.963666, fscore: 0.969100
2025-0509 21:08:02 INFO     在测试集上评估...
2025-0509 21:08:02 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:08:11 INFO     测试集 - precision: 0.976676, recall: 0.966173, fscore: 0.971396
2025-0509 21:08:12 INFO     发现更好的模型，已保存至 ./save/best_model_bert_bilstm_crf.pkl
2025-0509 21:08:12 INFO     模型已保存至 ./save/model_bert_bilstm_crf_epoch0.pkl
2025-0509 21:18:38 DEBUG    epoch 1-step 1000 loss: 2.615771
2025-0509 21:18:38 INFO     Step 1000: 开始验证...
2025-0509 21:18:38 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:19:24 INFO     Step 1000 验证结果 - precision: 0.9793, recall: 0.9760, fscore: 0.9776
2025-0509 21:20:12 INFO     在验证集上评估...
2025-0509 21:20:12 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:21:02 INFO     验证集 - precision: 0.980345, recall: 0.974135, fscore: 0.977230
2025-0509 21:21:02 INFO     在测试集上评估...
2025-0509 21:21:02 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:21:12 INFO     测试集 - precision: 0.981190, recall: 0.975432, fscore: 0.978303
2025-0509 21:21:13 INFO     发现更好的模型，已保存至 ./save/best_model_bert_bilstm_crf.pkl
2025-0509 21:21:14 INFO     模型已保存至 ./save/model_bert_bilstm_crf_epoch1.pkl
2025-0509 21:31:49 DEBUG    epoch 2-step 1000 loss: 1.791714
2025-0509 21:31:49 INFO     Step 1000: 开始验证...
2025-0509 21:31:49 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:32:33 INFO     Step 1000 验证结果 - precision: 0.9821, recall: 0.9778, fscore: 0.9800
2025-0509 21:33:17 INFO     在验证集上评估...
2025-0509 21:33:17 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:34:02 INFO     验证集 - precision: 0.982931, recall: 0.975796, fscore: 0.979350
2025-0509 21:34:02 INFO     在测试集上评估...
2025-0509 21:34:02 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:34:11 INFO     测试集 - precision: 0.984907, recall: 0.977655, fscore: 0.981268
2025-0509 21:34:11 INFO     发现更好的模型，已保存至 ./save/best_model_bert_bilstm_crf.pkl
2025-0509 21:34:12 INFO     模型已保存至 ./save/model_bert_bilstm_crf_epoch2.pkl
2025-0509 21:42:46 DEBUG    epoch 3-step 1000 loss: 1.337498
2025-0509 21:42:46 INFO     Step 1000: 开始验证...
2025-0509 21:42:46 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:43:43 INFO     Step 1000 验证结果 - precision: 0.9838, recall: 0.9789, fscore: 0.9813
2025-0509 21:44:28 INFO     在验证集上评估...
2025-0509 21:44:28 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:45:14 INFO     验证集 - precision: 0.983448, recall: 0.979348, fscore: 0.981394
2025-0509 21:45:14 INFO     在测试集上评估...
2025-0509 21:45:14 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:45:22 INFO     测试集 - precision: 0.985270, recall: 0.980171, fscore: 0.982714
2025-0509 21:45:23 INFO     发现更好的模型，已保存至 ./save/best_model_bert_bilstm_crf.pkl
2025-0509 21:45:23 INFO     模型已保存至 ./save/model_bert_bilstm_crf_epoch3.pkl
2025-0509 21:54:30 DEBUG    epoch 4-step 1000 loss: 1.089959
2025-0509 21:54:30 INFO     Step 1000: 开始验证...
2025-0509 21:54:30 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:55:37 INFO     Step 1000 验证结果 - precision: 0.9844, recall: 0.9797, fscore: 0.9820
2025-0509 21:56:32 INFO     在验证集上评估...
2025-0509 21:56:32 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:57:30 INFO     验证集 - precision: 0.984372, recall: 0.979973, fscore: 0.982168
2025-0509 21:57:30 INFO     在测试集上评估...
2025-0509 21:57:30 DEBUG    id2tag type: <class 'list'>, content: ['B', 'M', 'E', 'S', 'O']
2025-0509 21:57:38 INFO     测试集 - precision: 0.986258, recall: 0.981009, fscore: 0.983626
2025-0509 21:57:38 INFO     发现更好的模型，已保存至 ./save/best_model_bert_bilstm_crf.pkl
2025-0509 21:57:39 INFO     模型已保存至 ./save/model_bert_bilstm_crf_epoch4.pkl
